app:
  name: swg-llm
  mode: interactive
runtime:
  timeoutMs: 30000
  defaultProfile: cpu-low-memory
  defaultContextWindowTokens: 2048
  defaultTemperature: 0.0
  defaultTopP: 1.0
  defaultMaxTokens: 256
  defaultRetrievalChunks: 4
  profiles:
    cpu-low-memory:
      model: phi-3-mini-4k-instruct-q4
      backend: cpu
      contextWindowTokens: 2048
      retrievalChunks: 4
      temperature: 0.0
      topP: 1.0
      maxTokens: 256
    intel-igpu:
      model: phi-3-mini-4k-instruct-q4
      backend: openvino-onednn-igpu
      contextWindowTokens: 3072
      retrievalChunks: 5
      temperature: 0.0
      topP: 1.0
      maxTokens: 256
continuous:
  ingestIntervalMs: 120000
  improveIntervalMs: 300000
  maxRetries: 3
  retryBackoffMs: 5000
  maxCycles: 0
  maxRuntimeMs: 0
  idleTimeoutMs: 0
  statePath: .swgllm/continuous-state.json

autopublish:
  enabled: true
  targetRepoUrl: https://github.com/polsommer/llm-dsrc.git
  workspacePath: .swgllm/autopublish/workspace
  allowedBranches:
    - main
  requiredMinScoreDelta: 0.02
  maxPushesPerDay: 3
  manualApprovalForHighImpactChanges: false
  dryRun: false
